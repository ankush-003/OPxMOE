{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59094,"databundleVersionId":7010844,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using{device}')\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-26T14:04:56.034212Z","iopub.execute_input":"2024-08-26T14:04:56.035060Z","iopub.status.idle":"2024-08-26T14:05:00.722521Z","shell.execute_reply.started":"2024-08-26T14:04:56.035027Z","shell.execute_reply":"2024-08-26T14:05:00.721485Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/open-problems-single-cell-perturbations/multiome_train.parquet\n/kaggle/input/open-problems-single-cell-perturbations/multiome_obs_meta.csv\n/kaggle/input/open-problems-single-cell-perturbations/sample_submission.csv\n/kaggle/input/open-problems-single-cell-perturbations/adata_train.parquet\n/kaggle/input/open-problems-single-cell-perturbations/multiome_var_meta.csv\n/kaggle/input/open-problems-single-cell-perturbations/adata_obs_meta.csv\n/kaggle/input/open-problems-single-cell-perturbations/id_map.csv\n/kaggle/input/open-problems-single-cell-perturbations/de_train.parquet\n/kaggle/input/open-problems-single-cell-perturbations/adata_excluded_ids.csv\nUsingcuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet('../input/open-problems-single-cell-perturbations/de_train.parquet')\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:10.930565Z","iopub.execute_input":"2024-08-26T14:07:10.930939Z","iopub.status.idle":"2024-08-26T14:07:12.354944Z","shell.execute_reply.started":"2024-08-26T14:07:10.930912Z","shell.execute_reply":"2024-08-26T14:07:12.353762Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"              cell_type       sm_name sm_lincs_id  \\\n609  T regulatory cells  Atorvastatin    LSM-5771   \n610            NK cells     Riociguat   LSM-45758   \n611        T cells CD4+     Riociguat   LSM-45758   \n612        T cells CD8+     Riociguat   LSM-45758   \n613  T regulatory cells     Riociguat   LSM-45758   \n\n                                                SMILES  control      A1BG  \\\n609  CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F...    False -0.014372   \n610  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False -0.455549   \n611  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False  0.338168   \n612  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False  0.101138   \n613  COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...    False -0.757116   \n\n     A1BG-AS1       A2M   A2M-AS1     A2MP1  ...      ZUP1      ZW10  \\\n609 -0.122464 -0.456366 -0.147894 -0.545382  ... -0.549987 -2.200925   \n610  0.188181  0.595734 -0.100299  0.786192  ... -1.236905  0.003854   \n611 -0.109079  0.270182 -0.436586 -0.069476  ...  0.077579 -1.101637   \n612 -0.409724 -0.606292 -0.071300 -0.001789  ...  0.005951 -0.893093   \n613  0.085910 -0.730025 -1.367801 -0.695944  ...  0.232343 -2.247816   \n\n       ZWILCH     ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX  \\\n609  0.359806  1.073983  0.356939 -0.029603 -0.528817  0.105138  0.491015   \n610 -0.197569 -0.175307  0.101391  1.028394  0.034144 -0.231642  1.023994   \n611  0.457201  0.535184 -0.198404 -0.005004  0.552810 -0.209077  0.389751   \n612 -1.003029 -0.080367 -0.076604  0.024849  0.012862 -0.029684  0.005506   \n613 -0.346036 -0.919567 -1.131372 -0.120252 -0.064537 -0.603280 -0.098041   \n\n        ZZEF1  \n609 -0.979951  \n610 -0.064760  \n611 -0.337082  \n612 -1.733112  \n613 -0.750681  \n\n[5 rows x 18216 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_type</th>\n      <th>sm_name</th>\n      <th>sm_lincs_id</th>\n      <th>SMILES</th>\n      <th>control</th>\n      <th>A1BG</th>\n      <th>A1BG-AS1</th>\n      <th>A2M</th>\n      <th>A2M-AS1</th>\n      <th>A2MP1</th>\n      <th>...</th>\n      <th>ZUP1</th>\n      <th>ZW10</th>\n      <th>ZWILCH</th>\n      <th>ZWINT</th>\n      <th>ZXDA</th>\n      <th>ZXDB</th>\n      <th>ZXDC</th>\n      <th>ZYG11B</th>\n      <th>ZYX</th>\n      <th>ZZEF1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>609</th>\n      <td>T regulatory cells</td>\n      <td>Atorvastatin</td>\n      <td>LSM-5771</td>\n      <td>CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F...</td>\n      <td>False</td>\n      <td>-0.014372</td>\n      <td>-0.122464</td>\n      <td>-0.456366</td>\n      <td>-0.147894</td>\n      <td>-0.545382</td>\n      <td>...</td>\n      <td>-0.549987</td>\n      <td>-2.200925</td>\n      <td>0.359806</td>\n      <td>1.073983</td>\n      <td>0.356939</td>\n      <td>-0.029603</td>\n      <td>-0.528817</td>\n      <td>0.105138</td>\n      <td>0.491015</td>\n      <td>-0.979951</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>NK cells</td>\n      <td>Riociguat</td>\n      <td>LSM-45758</td>\n      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n      <td>False</td>\n      <td>-0.455549</td>\n      <td>0.188181</td>\n      <td>0.595734</td>\n      <td>-0.100299</td>\n      <td>0.786192</td>\n      <td>...</td>\n      <td>-1.236905</td>\n      <td>0.003854</td>\n      <td>-0.197569</td>\n      <td>-0.175307</td>\n      <td>0.101391</td>\n      <td>1.028394</td>\n      <td>0.034144</td>\n      <td>-0.231642</td>\n      <td>1.023994</td>\n      <td>-0.064760</td>\n    </tr>\n    <tr>\n      <th>611</th>\n      <td>T cells CD4+</td>\n      <td>Riociguat</td>\n      <td>LSM-45758</td>\n      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n      <td>False</td>\n      <td>0.338168</td>\n      <td>-0.109079</td>\n      <td>0.270182</td>\n      <td>-0.436586</td>\n      <td>-0.069476</td>\n      <td>...</td>\n      <td>0.077579</td>\n      <td>-1.101637</td>\n      <td>0.457201</td>\n      <td>0.535184</td>\n      <td>-0.198404</td>\n      <td>-0.005004</td>\n      <td>0.552810</td>\n      <td>-0.209077</td>\n      <td>0.389751</td>\n      <td>-0.337082</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>T cells CD8+</td>\n      <td>Riociguat</td>\n      <td>LSM-45758</td>\n      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n      <td>False</td>\n      <td>0.101138</td>\n      <td>-0.409724</td>\n      <td>-0.606292</td>\n      <td>-0.071300</td>\n      <td>-0.001789</td>\n      <td>...</td>\n      <td>0.005951</td>\n      <td>-0.893093</td>\n      <td>-1.003029</td>\n      <td>-0.080367</td>\n      <td>-0.076604</td>\n      <td>0.024849</td>\n      <td>0.012862</td>\n      <td>-0.029684</td>\n      <td>0.005506</td>\n      <td>-1.733112</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>T regulatory cells</td>\n      <td>Riociguat</td>\n      <td>LSM-45758</td>\n      <td>COC(=O)N(C)c1c(N)nc(-c2nn(Cc3ccccc3F)c3ncccc23...</td>\n      <td>False</td>\n      <td>-0.757116</td>\n      <td>0.085910</td>\n      <td>-0.730025</td>\n      <td>-1.367801</td>\n      <td>-0.695944</td>\n      <td>...</td>\n      <td>0.232343</td>\n      <td>-2.247816</td>\n      <td>-0.346036</td>\n      <td>-0.919567</td>\n      <td>-1.131372</td>\n      <td>-0.120252</td>\n      <td>-0.064537</td>\n      <td>-0.603280</td>\n      <td>-0.098041</td>\n      <td>-0.750681</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 18216 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"column_array = df['SMILES'].values","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:12.356826Z","iopub.execute_input":"2024-08-26T14:07:12.357177Z","iopub.status.idle":"2024-08-26T14:07:12.362359Z","shell.execute_reply.started":"2024-08-26T14:07:12.357145Z","shell.execute_reply":"2024-08-26T14:07:12.361473Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"##column_array","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:11:08.615543Z","iopub.execute_input":"2024-07-11T14:11:08.615781Z","iopub.status.idle":"2024-07-11T14:11:08.623361Z","shell.execute_reply.started":"2024-07-11T14:11:08.615760Z","shell.execute_reply":"2024-07-11T14:11:08.622423Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"markdown","source":"# Building Experts","metadata":{}},{"cell_type":"markdown","source":"# final trial","metadata":{}},{"cell_type":"code","source":"feature_cols =['cell_type','sm_name']\ntarget_cols = ['cell_type','sm_name','sm_lincs_id','SMILES','control']\ntargets = df.drop(columns=target_cols)\nfeatures = pd.DataFrame(df,columns=feature_cols)\nfeatures","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:16.846017Z","iopub.execute_input":"2024-08-26T14:07:16.846650Z","iopub.status.idle":"2024-08-26T14:07:16.891979Z","shell.execute_reply.started":"2024-08-26T14:07:16.846621Z","shell.execute_reply":"2024-08-26T14:07:16.890911Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"              cell_type             sm_name\n0              NK cells        Clotrimazole\n1          T cells CD4+        Clotrimazole\n2          T cells CD8+        Clotrimazole\n3    T regulatory cells        Clotrimazole\n4              NK cells  Mometasone Furoate\n..                  ...                 ...\n609  T regulatory cells        Atorvastatin\n610            NK cells           Riociguat\n611        T cells CD4+           Riociguat\n612        T cells CD8+           Riociguat\n613  T regulatory cells           Riociguat\n\n[614 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_type</th>\n      <th>sm_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NK cells</td>\n      <td>Clotrimazole</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>T cells CD4+</td>\n      <td>Clotrimazole</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T cells CD8+</td>\n      <td>Clotrimazole</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>T regulatory cells</td>\n      <td>Clotrimazole</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NK cells</td>\n      <td>Mometasone Furoate</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>T regulatory cells</td>\n      <td>Atorvastatin</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>NK cells</td>\n      <td>Riociguat</td>\n    </tr>\n    <tr>\n      <th>611</th>\n      <td>T cells CD4+</td>\n      <td>Riociguat</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>T cells CD8+</td>\n      <td>Riociguat</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>T regulatory cells</td>\n      <td>Riociguat</td>\n    </tr>\n  </tbody>\n</table>\n<p>614 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\none_hot = OneHotEncoder()\nfeatures_array = one_hot.fit_transform(features)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:18.648233Z","iopub.execute_input":"2024-08-26T14:07:18.648583Z","iopub.status.idle":"2024-08-26T14:07:19.102443Z","shell.execute_reply.started":"2024-08-26T14:07:18.648551Z","shell.execute_reply":"2024-08-26T14:07:19.101405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"features_array.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:20.961037Z","iopub.execute_input":"2024-08-26T14:07:20.961976Z","iopub.status.idle":"2024-08-26T14:07:20.967855Z","shell.execute_reply.started":"2024-08-26T14:07:20.961941Z","shell.execute_reply":"2024-08-26T14:07:20.966771Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(614, 152)"},"metadata":{}}]},{"cell_type":"code","source":"features_one_hot=features_array\nprint(features_one_hot.toarray().shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:21.383097Z","iopub.execute_input":"2024-08-26T14:07:21.383482Z","iopub.status.idle":"2024-08-26T14:07:21.389979Z","shell.execute_reply.started":"2024-08-26T14:07:21.383452Z","shell.execute_reply":"2024-08-26T14:07:21.388975Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(614, 152)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into 70% training, 15% validation, and 15% testing\nX_train, X_temp, y_train, y_temp = train_test_split(features_one_hot, targets.values, test_size=0.1, shuffle=False)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:21.770065Z","iopub.execute_input":"2024-08-26T14:07:21.770438Z","iopub.status.idle":"2024-08-26T14:07:21.927988Z","shell.execute_reply.started":"2024-08-26T14:07:21.770410Z","shell.execute_reply":"2024-08-26T14:07:21.927090Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"featurespace = features_one_hot.toarray()\ntargetsspace = targets.values\ntargetsspace.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:22.143268Z","iopub.execute_input":"2024-08-26T14:07:22.143761Z","iopub.status.idle":"2024-08-26T14:07:22.150655Z","shell.execute_reply.started":"2024-08-26T14:07:22.143730Z","shell.execute_reply":"2024-08-26T14:07:22.149768Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(614, 18211)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader,Dataset\nclass dataset(Dataset):\n    def __init__(self,X_train,y_train):\n        self.X_train=X_train\n        self.y_train=y_train\n    def __len__(self):\n        return len(self.X_train)\n    def __getitem__(self,idx):\n        return self.X_train[idx], self.y_train[idx]","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:22.569033Z","iopub.execute_input":"2024-08-26T14:07:22.569418Z","iopub.status.idle":"2024-08-26T14:07:22.575353Z","shell.execute_reply.started":"2024-08-26T14:07:22.569388Z","shell.execute_reply":"2024-08-26T14:07:22.574290Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfeatures_t= torch.tensor(featurespace).to(device)\ntarget_t=torch.tensor(targetsspace).to(device)\ndata=dataset(features_t,target_t)\ntarget_t.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:23.009833Z","iopub.execute_input":"2024-08-26T14:07:23.010182Z","iopub.status.idle":"2024-08-26T14:07:23.242598Z","shell.execute_reply.started":"2024-08-26T14:07:23.010155Z","shell.execute_reply":"2024-08-26T14:07:23.241717Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([614, 18211])"},"metadata":{}}]},{"cell_type":"code","source":"batchsize=64\ndataloader = torch.utils.data.DataLoader(data,batch_size=batchsize,shuffle=True)\nfor batch,(x,y) in enumerate(dataloader):\n    print('batch',batch,x.shape,y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:23.493676Z","iopub.execute_input":"2024-08-26T14:07:23.494022Z","iopub.status.idle":"2024-08-26T14:07:23.549704Z","shell.execute_reply.started":"2024-08-26T14:07:23.493996Z","shell.execute_reply":"2024-08-26T14:07:23.548830Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"batch 0 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 1 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 2 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 3 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 4 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 5 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 6 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 7 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 8 torch.Size([64, 152]) torch.Size([64, 18211])\nbatch 9 torch.Size([38, 152]) torch.Size([38, 18211])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport numpy as np\nfrom scipy.sparse import issparse\n\n# Define custom loss function\nclass LogCoshLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n    \n    def forward(self, y_prime_t, y_t):\n        ey_t = (y_t - y_prime_t) / 3  # divide by 3 to avoid numerical overflow in cosh\n        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n\n# Define expert models\nclass Conv(nn.Module):\n    def __init__(self, scheme, input_channels=1):\n        super(Conv, self).__init__()\n        self.name = 'Conv'\n        self.conv_block = nn.Sequential(\n            nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.AdaptiveAvgPool1d(1),\n            nn.Flatten())\n        self.linear = nn.Sequential(\n            nn.Linear(128, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.head1 = nn.Linear(512, output_size)\n        \n    def forward(self, x):\n        # Ensure input is 3D: (batch_size, channels, sequence_length)\n        if x.dim() == 2:\n            x = x.unsqueeze(1)\n        out = self.conv_block(x)\n        out = self.linear(out)\n        out = self.head1(out)\n        return out\n\nclass LSTM(nn.Module):\n    def __init__(self, scheme, input_size, output_size):\n        super(LSTM, self).__init__()\n        self.name = 'LSTM'\n        self.lstm = nn.LSTM(input_size, 128, num_layers=2, batch_first=True)\n        self.linear = nn.Sequential(\n            nn.Linear(128, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.head1 = nn.Linear(512, output_size)\n        \n    def forward(self, x):\n        # Ensure input is 3D: (batch_size, sequence_length, input_size)\n        if x.dim() == 2:\n            x = x.unsqueeze(1)  # Add sequence dimension\n        \n        batch_size, seq_len, _ = x.size()\n        \n        out, (hn, cn) = self.lstm(x)\n        \n        if seq_len == 1:\n            out = out.squeeze(1)  # Remove sequence dimension if it's 1\n        else:\n            out = out[:, -1, :]  # Take the last time step\n        \n        out = self.linear(out)\n        out = self.head1(out)\n        return out\n\nclass GRU(nn.Module):\n    def __init__(self, scheme, input_size, output_size):\n        super(GRU, self).__init__()\n        self.name = 'GRU'\n        self.gru = nn.GRU(input_size, 128, num_layers=2, batch_first=True)\n        self.linear = nn.Sequential(\n            nn.Linear(128, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        self.head1 = nn.Linear(512, output_size)\n        \n    def forward(self, x):\n        # Ensure input is 3D: (batch_size, sequence_length, input_size)\n        if x.dim() == 2:\n            x = x.unsqueeze(1)  # Add sequence dimension\n        \n        batch_size, seq_len, _ = x.size()\n        \n        out, hn = self.gru(x)\n        \n        if seq_len == 1:\n            out = out.squeeze(1)  # Remove sequence dimension if it's 1\n        else:\n            out = out[:, -1, :]  # Take the last time step\n        \n        out = self.linear(out)\n        out = self.head1(out)\n        return out\n\n# Define Gating Network\nclass GatingNetwork(nn.Module):\n    def __init__(self, input_size, num_experts):\n        super(GatingNetwork, self).__init__()\n        self.linear1 = nn.Linear(input_size, 64)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(64, num_experts)\n        self.softmax = nn.Softmax(dim=-1)\n    \n    def forward(self, data):\n        x = self.linear1(data)\n        x = self.relu(x)\n        x = self.linear2(x)\n        x = self.softmax(x)\n        return x\n\n# Define Mixture of Experts model\nclass MixtureOfExperts(nn.Module):\n    def __init__(self, input_size, output_size, scheme):\n        super(MixtureOfExperts, self).__init__()\n        self.experts = nn.ModuleList([\n            Conv(scheme, input_channels=1),\n            LSTM(scheme, input_size, output_size),\n            GRU(scheme, input_size, output_size)\n        ])\n        self.gating_network = GatingNetwork(input_size, len(self.experts))\n        self.loss1 = nn.MSELoss()\n        self.loss2 = LogCoshLoss()\n        self.loss3 = nn.L1Loss()\n        self.loss4 = nn.BCELoss()\n    \n    def forward(self, data, y=None):\n        data = data.float()\n        \n        gating_weights = self.gating_network(data)\n        \n        expert_outputs = []\n        for i, expert in enumerate(self.experts):\n            if i == 0:  # Conv\n                expert_input = data.unsqueeze(1) if data.dim() == 2 else data\n            else:  # LSTM and GRU\n                expert_input = data if data.dim() == 3 else data.unsqueeze(1)\n            \n            output = expert(expert_input)\n            expert_outputs.append(output)\n        \n        expert_outputs = torch.stack(expert_outputs, dim=1)\n        combined_output = torch.sum(expert_outputs * gating_weights.unsqueeze(-1), dim=1)\n        \n        if y is None:\n            return combined_output\n        else:\n            y = y.float()\n            loss1 = 0.4 * self.loss1(combined_output, y) + 0.3 * self.loss2(combined_output, y) + 0.3 * self.loss3(combined_output, y)\n            yhat = torch.sigmoid(combined_output)\n            yy = torch.sigmoid(y)\n            loss2 = self.loss4(yhat, yy)\n            return 0.8 * loss1 + 0.2 * loss2\n# Define RMSE rowwise loss\ndef RMSE_rowwise_loss(model, data, y_true):\n    model.eval()\n    with torch.no_grad():\n        y_pred_original = model(data.float())\n    mae = mean_absolute_error(y_true.numpy(), y_pred_original.numpy())\n    rowwise_rmse = np.sqrt(np.mean(np.square(y_true.numpy() - y_pred_original.numpy()), axis=1))\n    mrrmse_score = np.mean(rowwise_rmse)\n    return mrrmse_score\n\n# Usage\ninput_size = 152\noutput_size = 18211\nscheme = 'initial'\nepochs = 2000\n\nmodel = MixtureOfExperts(input_size, output_size, scheme)\nmodel = model.float()\nmodel = model.to(device)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:23.909799Z","iopub.execute_input":"2024-08-26T14:07:23.910127Z","iopub.status.idle":"2024-08-26T14:07:26.958291Z","shell.execute_reply.started":"2024-08-26T14:07:23.910103Z","shell.execute_reply":"2024-08-26T14:07:26.957495Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:13:41.317195Z","iopub.execute_input":"2024-08-26T14:13:41.317963Z","iopub.status.idle":"2024-08-26T14:13:41.324296Z","shell.execute_reply.started":"2024-08-26T14:13:41.317930Z","shell.execute_reply":"2024-08-26T14:13:41.322697Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"MixtureOfExperts(\n  (experts): ModuleList(\n    (0): Conv(\n      (conv_block): Sequential(\n        (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n        (6): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n        (7): ReLU()\n        (8): Dropout(p=0.3, inplace=False)\n        (9): AdaptiveAvgPool1d(output_size=1)\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n    (1): LSTM(\n      (lstm): LSTM(152, 128, num_layers=2, batch_first=True)\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n    (2): GRU(\n      (gru): GRU(152, 128, num_layers=2, batch_first=True)\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n  )\n  (gating_network): GatingNetwork(\n    (linear1): Linear(in_features=152, out_features=64, bias=True)\n    (relu): ReLU()\n    (linear2): Linear(in_features=64, out_features=3, bias=True)\n    (softmax): Softmax(dim=-1)\n  )\n  (loss1): MSELoss()\n  (loss2): LogCoshLoss()\n  (loss3): L1Loss()\n  (loss4): BCELoss()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"import logging\n# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef train_model(model, data, optimizer, epochs, batch_size, device):\n    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n    \n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        total_batches = 0\n        \n        for batch, (x, y) in enumerate(dataloader):\n            x = x.float().to(device)\n            y = y.float().to(device)\n            \n            optimizer.zero_grad()\n            try:\n                loss = model(x, y)\n                loss.backward()\n                optimizer.step()\n                \n                epoch_loss += loss.item()\n                total_batches += 1\n            except RuntimeError as e:\n                print(f\"Error in epoch {epoch+1}, batch {batch+1}: {str(e)}\")\n                print(f\"Input shapes: x: {x.shape}, y: {y.shape}\")\n                continue\n        \n        avg_loss = epoch_loss / total_batches\n        print(f'Epoch {epoch+1}/{epochs} completed. Average loss: {avg_loss:.4f}')\n\n# Usage\nepochs = 2000\nbatch_size = 64\ntrain_model(model, data, optimizer, epochs, batch_size, device)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:07:26.959697Z","iopub.execute_input":"2024-08-26T14:07:26.960109Z","iopub.status.idle":"2024-08-26T14:07:37.510116Z","shell.execute_reply.started":"2024-08-26T14:07:26.960083Z","shell.execute_reply":"2024-08-26T14:07:37.508814Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/2000 completed. Average loss: 2.1198\nEpoch 2/2000 completed. Average loss: 2.2367\nEpoch 3/2000 completed. Average loss: 2.1340\nEpoch 4/2000 completed. Average loss: 2.0878\nEpoch 5/2000 completed. Average loss: 1.9561\nEpoch 6/2000 completed. Average loss: 1.8084\nEpoch 7/2000 completed. Average loss: 1.8088\nEpoch 8/2000 completed. Average loss: 1.5400\nEpoch 9/2000 completed. Average loss: 1.4963\nEpoch 10/2000 completed. Average loss: 1.5017\nEpoch 11/2000 completed. Average loss: 1.4245\nEpoch 12/2000 completed. Average loss: 1.4185\nEpoch 13/2000 completed. Average loss: 1.4239\nEpoch 14/2000 completed. Average loss: 1.4101\nEpoch 15/2000 completed. Average loss: 1.3819\nEpoch 16/2000 completed. Average loss: 1.3663\nEpoch 17/2000 completed. Average loss: 1.3464\nEpoch 18/2000 completed. Average loss: 1.3661\nEpoch 19/2000 completed. Average loss: 1.2626\nEpoch 20/2000 completed. Average loss: 1.2809\nEpoch 21/2000 completed. Average loss: 1.1980\nEpoch 22/2000 completed. Average loss: 1.1786\nEpoch 23/2000 completed. Average loss: 1.1510\nEpoch 24/2000 completed. Average loss: 1.1623\nEpoch 25/2000 completed. Average loss: 1.1134\nEpoch 26/2000 completed. Average loss: 1.0736\nEpoch 27/2000 completed. Average loss: 1.0481\nEpoch 28/2000 completed. Average loss: 1.0199\nEpoch 29/2000 completed. Average loss: 1.0048\nEpoch 30/2000 completed. Average loss: 1.0323\nEpoch 31/2000 completed. Average loss: 0.9848\nEpoch 32/2000 completed. Average loss: 0.9752\nEpoch 33/2000 completed. Average loss: 0.9637\nEpoch 34/2000 completed. Average loss: 0.9598\nEpoch 35/2000 completed. Average loss: 0.9596\nEpoch 36/2000 completed. Average loss: 1.0014\nEpoch 37/2000 completed. Average loss: 0.9527\nEpoch 38/2000 completed. Average loss: 0.9248\nEpoch 39/2000 completed. Average loss: 0.9252\nEpoch 40/2000 completed. Average loss: 0.9045\nEpoch 41/2000 completed. Average loss: 0.8972\nEpoch 42/2000 completed. Average loss: 0.9071\nEpoch 43/2000 completed. Average loss: 0.9008\nEpoch 44/2000 completed. Average loss: 0.8684\nEpoch 45/2000 completed. Average loss: 0.8911\nEpoch 46/2000 completed. Average loss: 0.9114\nEpoch 47/2000 completed. Average loss: 0.9063\nEpoch 48/2000 completed. Average loss: 0.9161\nEpoch 49/2000 completed. Average loss: 0.8762\nEpoch 50/2000 completed. Average loss: 0.8813\nEpoch 51/2000 completed. Average loss: 0.8630\nEpoch 52/2000 completed. Average loss: 0.9219\nEpoch 53/2000 completed. Average loss: 0.8642\nEpoch 54/2000 completed. Average loss: 0.8525\nEpoch 55/2000 completed. Average loss: 0.8734\nEpoch 56/2000 completed. Average loss: 0.8860\nEpoch 57/2000 completed. Average loss: 0.8201\nEpoch 58/2000 completed. Average loss: 0.8575\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m     35\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data, optimizer, epochs, batch_size, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[15], line 155\u001b[0m, in \u001b[0;36mMixtureOfExperts.forward\u001b[0;34m(self, data, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 155\u001b[0m     gating_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgating_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     expert_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, expert \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperts):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[15], line 132\u001b[0m, in \u001b[0;36mGatingNetwork.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(data)\n\u001b[0;32m--> 132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n\u001b[1;32m    134\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1466\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelu\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"relu(input, inplace=False) -> Tensor\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    Applies the rectified linear unit function element-wise. See\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    :class:`~torch.nn.ReLU` for more details.\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function_unary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1467\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import torch.optim as optim\n# from torch.autograd import Variable\n\n# input_size = 152\n# output_size = 18211\n# num_experts = 5\n# epochs = 200\n\n# # Create the model\n# model = MixtureOfExperts(input_size, output_size, num_experts)\n\n# # Define the optimizer\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# for epoch in range(0, epochs):\n#     for batch, (feature_train, target_train) in enumerate(dataloader):\n#         optimizer.zero_grad()\n#         loss = RMSE_rowwise_loss(model, feature_train.float(), target_train.float())\n#         loss = Variable(torch.tensor(loss), requires_grad=True)\n#         loss.backward()\n#         optimizer.step()\n#     if epoch % 5 == 0:\n#         print(f\"epoch: {epoch + 1} loss: {loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:49:44.939854Z","iopub.execute_input":"2024-07-11T09:49:44.940208Z","iopub.status.idle":"2024-07-11T09:49:44.944982Z","shell.execute_reply.started":"2024-07-11T09:49:44.940180Z","shell.execute_reply":"2024-07-11T09:49:44.944037Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"id_map = pd.read_csv(\"/kaggle/input/open-problems-single-cell-perturbations/id_map.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:39.007994Z","iopub.execute_input":"2024-07-11T14:17:39.008721Z","iopub.status.idle":"2024-07-11T14:17:39.028727Z","shell.execute_reply.started":"2024-07-11T14:17:39.008688Z","shell.execute_reply":"2024-07-11T14:17:39.027987Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"testdata = pd.DataFrame(id_map,columns=feature_cols) \n#testdata.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:40.249825Z","iopub.execute_input":"2024-07-11T14:17:40.250216Z","iopub.status.idle":"2024-07-11T14:17:40.255337Z","shell.execute_reply.started":"2024-07-11T14:17:40.250161Z","shell.execute_reply":"2024-07-11T14:17:40.254365Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"one_hot_test = one_hot.transform(testdata)\nprint(features_one_hot.toarray().shape,one_hot_test.toarray().shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:42.359811Z","iopub.execute_input":"2024-07-11T14:17:42.360451Z","iopub.status.idle":"2024-07-11T14:17:42.368120Z","shell.execute_reply.started":"2024-07-11T14:17:42.360417Z","shell.execute_reply":"2024-07-11T14:17:42.367038Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(614, 152) (255, 152)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\ntarget_pred = model(torch.Tensor(one_hot_test.toarray()).to(device))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:45.445530Z","iopub.execute_input":"2024-07-11T14:17:45.445892Z","iopub.status.idle":"2024-07-11T14:17:45.460540Z","shell.execute_reply.started":"2024-07-11T14:17:45.445863Z","shell.execute_reply":"2024-07-11T14:17:45.459693Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"res = target_pred.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:46.915622Z","iopub.execute_input":"2024-07-11T14:17:46.916242Z","iopub.status.idle":"2024-07-11T14:17:46.935250Z","shell.execute_reply.started":"2024-07-11T14:17:46.916199Z","shell.execute_reply":"2024-07-11T14:17:46.934540Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:47.914111Z","iopub.execute_input":"2024-07-11T14:17:47.914998Z","iopub.status.idle":"2024-07-11T14:17:47.921989Z","shell.execute_reply.started":"2024-07-11T14:17:47.914965Z","shell.execute_reply":"2024-07-11T14:17:47.921047Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"MixtureOfExperts(\n  (experts): ModuleList(\n    (0): Conv(\n      (conv_block): Sequential(\n        (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n        (6): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n        (7): ReLU()\n        (8): Dropout(p=0.3, inplace=False)\n        (9): AdaptiveAvgPool1d(output_size=1)\n        (10): Flatten(start_dim=1, end_dim=-1)\n      )\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n    (1): LSTM(\n      (lstm): LSTM(152, 128, num_layers=2, batch_first=True)\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n    (2): GRU(\n      (gru): GRU(152, 128, num_layers=2, batch_first=True)\n      (linear): Sequential(\n        (0): Linear(in_features=128, out_features=512, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.3, inplace=False)\n        (3): Linear(in_features=512, out_features=512, bias=True)\n        (4): ReLU()\n        (5): Dropout(p=0.3, inplace=False)\n      )\n      (head1): Linear(in_features=512, out_features=18211, bias=True)\n    )\n  )\n  (gating_network): GatingNetwork(\n    (linear1): Linear(in_features=152, out_features=64, bias=True)\n    (relu): ReLU()\n    (linear2): Linear(in_features=64, out_features=3, bias=True)\n    (softmax): Softmax(dim=-1)\n  )\n  (loss1): MSELoss()\n  (loss2): LogCoshLoss()\n  (loss3): L1Loss()\n  (loss4): BCELoss()\n)"},"metadata":{}}]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/open-problems-single-cell-perturbations/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:53.576805Z","iopub.execute_input":"2024-07-11T14:17:53.577190Z","iopub.status.idle":"2024-07-11T14:17:56.489448Z","shell.execute_reply.started":"2024-07-11T14:17:53.577146Z","shell.execute_reply":"2024-07-11T14:17:56.488596Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"sample_columns = sample_submission.columns\nsample_columns= sample_columns[1:]\nsubmission_df = pd.DataFrame(res.detach().numpy(), columns=sample_columns)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:17:56.490843Z","iopub.execute_input":"2024-07-11T14:17:56.491138Z","iopub.status.idle":"2024-07-11T14:17:56.496412Z","shell.execute_reply.started":"2024-07-11T14:17:56.491112Z","shell.execute_reply":"2024-07-11T14:17:56.495436Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"submission_df.insert(0, 'id', range(255))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:18:03.019125Z","iopub.execute_input":"2024-07-11T14:18:03.019970Z","iopub.status.idle":"2024-07-11T14:18:03.028947Z","shell.execute_reply.started":"2024-07-11T14:18:03.019938Z","shell.execute_reply":"2024-07-11T14:18:03.027904Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:18:12.433991Z","iopub.execute_input":"2024-07-11T14:18:12.434373Z","iopub.status.idle":"2024-07-11T14:18:12.479556Z","shell.execute_reply.started":"2024-07-11T14:18:12.434341Z","shell.execute_reply":"2024-07-11T14:18:12.478683Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"      id  A1BG  A1BG-AS1  A2M  A2M-AS1  A2MP1  A4GALT  AAAS  AACS  AAGAB  ...  \\\n0      0   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n1      1   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n2      2   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n3      3   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n4      4   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n..   ...   ...       ...  ...      ...    ...     ...   ...   ...    ...  ...   \n250  250   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n251  251   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n252  252   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n253  253   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n254  254   0.0       0.0  0.0      0.0    0.0     0.0   0.0   0.0    0.0  ...   \n\n     ZUP1  ZW10  ZWILCH  ZWINT  ZXDA  ZXDB  ZXDC  ZYG11B  ZYX  ZZEF1  \n0     0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n1     0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n2     0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n3     0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n4     0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n..    ...   ...     ...    ...   ...   ...   ...     ...  ...    ...  \n250   0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n251   0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n252   0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n253   0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n254   0.0   0.0     0.0    0.0   0.0   0.0   0.0     0.0  0.0    0.0  \n\n[255 rows x 18212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>A1BG</th>\n      <th>A1BG-AS1</th>\n      <th>A2M</th>\n      <th>A2M-AS1</th>\n      <th>A2MP1</th>\n      <th>A4GALT</th>\n      <th>AAAS</th>\n      <th>AACS</th>\n      <th>AAGAB</th>\n      <th>...</th>\n      <th>ZUP1</th>\n      <th>ZW10</th>\n      <th>ZWILCH</th>\n      <th>ZWINT</th>\n      <th>ZXDA</th>\n      <th>ZXDB</th>\n      <th>ZXDC</th>\n      <th>ZYG11B</th>\n      <th>ZYX</th>\n      <th>ZZEF1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>250</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>251</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>252</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>253</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>254</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>255 rows Ã— 18212 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:18:16.221863Z","iopub.execute_input":"2024-07-11T14:18:16.222697Z","iopub.status.idle":"2024-07-11T14:18:16.252714Z","shell.execute_reply.started":"2024-07-11T14:18:16.222664Z","shell.execute_reply":"2024-07-11T14:18:16.251739Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"      id      A1BG  A1BG-AS1       A2M   A2M-AS1     A2MP1    A4GALT  \\\n0      0  0.325826 -0.007866  0.370508  0.661771  1.344700  0.952999   \n1      1  0.146974  0.055501  0.330907  0.320045  0.343979  0.171514   \n2      2  0.429456  0.060914  0.666287  1.160771  3.196780  2.379148   \n3      3 -0.044657 -0.017270  0.053793  0.155811  0.216723  0.003991   \n4      4  0.428918  0.016291  0.606734  0.789091  2.402305  1.698626   \n..   ...       ...       ...       ...       ...       ...       ...   \n250  250 -0.182730 -0.186048 -0.122282 -0.236606  1.192663  0.322482   \n251  251  0.166292  0.172093 -0.264903  0.312848  2.244164  0.697194   \n252  252  0.179165  0.050252 -1.559113 -0.208699  2.996405  1.089666   \n253  253  0.719092  1.957038 -9.073939 -1.067257  9.791842  9.566616   \n254  254  0.047629  0.026461 -3.082912 -0.203656  0.456576  0.884993   \n\n         AAAS      AACS     AAGAB  ...      ZUP1      ZW10    ZWILCH  \\\n0   -0.112421  0.013561 -0.186119  ... -0.712701 -0.251880 -0.117705   \n1   -0.107187  0.163914  0.414388  ...  0.436475  0.073368 -0.217088   \n2    0.338011  1.073238  0.860730  ... -0.026625  0.435995  1.161289   \n3   -0.174959 -0.062513 -0.023720  ... -0.192043 -0.026088 -0.167034   \n4   -0.052214 -0.135977  0.161543  ... -0.600954  0.254689  0.126396   \n..        ...       ...       ...  ...       ...       ...       ...   \n250  0.159350  0.261420  0.040568  ... -0.078092 -0.921257 -1.594355   \n251  0.063729 -0.061041 -0.336808  ... -0.447420 -0.489593 -0.637586   \n252  0.169657 -0.199713  0.011201  ... -0.272914 -0.772601 -1.286773   \n253  1.057602 -0.367063  0.284872  ... -1.418733 -1.232353 -4.137112   \n254  0.062528  0.145023  0.050536  ...  0.103100 -0.251306 -0.537388   \n\n        ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1  \n0    0.244854  0.316382  0.361226  0.317160  0.428898 -0.035407  0.042672  \n1    0.200419  0.118749  0.008344  0.174967  0.080371 -0.462454 -0.144866  \n2    1.409133  0.578077  0.798683  0.937108  0.019590 -0.292967 -0.044822  \n3   -0.116363  0.015246 -0.020211  0.122894  0.086638  0.061081 -0.124278  \n4    0.555928  0.636604  0.189434  0.461295  0.149743  0.065418  0.053007  \n..        ...       ...       ...       ...       ...       ...       ...  \n250 -0.888925 -0.196915 -0.390939 -0.629882 -0.303671 -1.398325 -0.638539  \n251 -0.570963  0.421161 -0.205135 -0.238691  0.157226 -0.744223 -0.297976  \n252 -0.605035  0.342517  0.162946 -0.581229 -0.558160 -0.167480 -0.208152  \n253  0.878891  2.284428  0.125582 -2.409629 -3.088445 -0.943358 -0.822677  \n254 -0.611182  0.294958 -0.166037 -0.286224 -0.185726 -0.943598 -0.283262  \n\n[255 rows x 18212 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>A1BG</th>\n      <th>A1BG-AS1</th>\n      <th>A2M</th>\n      <th>A2M-AS1</th>\n      <th>A2MP1</th>\n      <th>A4GALT</th>\n      <th>AAAS</th>\n      <th>AACS</th>\n      <th>AAGAB</th>\n      <th>...</th>\n      <th>ZUP1</th>\n      <th>ZW10</th>\n      <th>ZWILCH</th>\n      <th>ZWINT</th>\n      <th>ZXDA</th>\n      <th>ZXDB</th>\n      <th>ZXDC</th>\n      <th>ZYG11B</th>\n      <th>ZYX</th>\n      <th>ZZEF1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.325826</td>\n      <td>-0.007866</td>\n      <td>0.370508</td>\n      <td>0.661771</td>\n      <td>1.344700</td>\n      <td>0.952999</td>\n      <td>-0.112421</td>\n      <td>0.013561</td>\n      <td>-0.186119</td>\n      <td>...</td>\n      <td>-0.712701</td>\n      <td>-0.251880</td>\n      <td>-0.117705</td>\n      <td>0.244854</td>\n      <td>0.316382</td>\n      <td>0.361226</td>\n      <td>0.317160</td>\n      <td>0.428898</td>\n      <td>-0.035407</td>\n      <td>0.042672</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.146974</td>\n      <td>0.055501</td>\n      <td>0.330907</td>\n      <td>0.320045</td>\n      <td>0.343979</td>\n      <td>0.171514</td>\n      <td>-0.107187</td>\n      <td>0.163914</td>\n      <td>0.414388</td>\n      <td>...</td>\n      <td>0.436475</td>\n      <td>0.073368</td>\n      <td>-0.217088</td>\n      <td>0.200419</td>\n      <td>0.118749</td>\n      <td>0.008344</td>\n      <td>0.174967</td>\n      <td>0.080371</td>\n      <td>-0.462454</td>\n      <td>-0.144866</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.429456</td>\n      <td>0.060914</td>\n      <td>0.666287</td>\n      <td>1.160771</td>\n      <td>3.196780</td>\n      <td>2.379148</td>\n      <td>0.338011</td>\n      <td>1.073238</td>\n      <td>0.860730</td>\n      <td>...</td>\n      <td>-0.026625</td>\n      <td>0.435995</td>\n      <td>1.161289</td>\n      <td>1.409133</td>\n      <td>0.578077</td>\n      <td>0.798683</td>\n      <td>0.937108</td>\n      <td>0.019590</td>\n      <td>-0.292967</td>\n      <td>-0.044822</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-0.044657</td>\n      <td>-0.017270</td>\n      <td>0.053793</td>\n      <td>0.155811</td>\n      <td>0.216723</td>\n      <td>0.003991</td>\n      <td>-0.174959</td>\n      <td>-0.062513</td>\n      <td>-0.023720</td>\n      <td>...</td>\n      <td>-0.192043</td>\n      <td>-0.026088</td>\n      <td>-0.167034</td>\n      <td>-0.116363</td>\n      <td>0.015246</td>\n      <td>-0.020211</td>\n      <td>0.122894</td>\n      <td>0.086638</td>\n      <td>0.061081</td>\n      <td>-0.124278</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.428918</td>\n      <td>0.016291</td>\n      <td>0.606734</td>\n      <td>0.789091</td>\n      <td>2.402305</td>\n      <td>1.698626</td>\n      <td>-0.052214</td>\n      <td>-0.135977</td>\n      <td>0.161543</td>\n      <td>...</td>\n      <td>-0.600954</td>\n      <td>0.254689</td>\n      <td>0.126396</td>\n      <td>0.555928</td>\n      <td>0.636604</td>\n      <td>0.189434</td>\n      <td>0.461295</td>\n      <td>0.149743</td>\n      <td>0.065418</td>\n      <td>0.053007</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>250</td>\n      <td>-0.182730</td>\n      <td>-0.186048</td>\n      <td>-0.122282</td>\n      <td>-0.236606</td>\n      <td>1.192663</td>\n      <td>0.322482</td>\n      <td>0.159350</td>\n      <td>0.261420</td>\n      <td>0.040568</td>\n      <td>...</td>\n      <td>-0.078092</td>\n      <td>-0.921257</td>\n      <td>-1.594355</td>\n      <td>-0.888925</td>\n      <td>-0.196915</td>\n      <td>-0.390939</td>\n      <td>-0.629882</td>\n      <td>-0.303671</td>\n      <td>-1.398325</td>\n      <td>-0.638539</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>251</td>\n      <td>0.166292</td>\n      <td>0.172093</td>\n      <td>-0.264903</td>\n      <td>0.312848</td>\n      <td>2.244164</td>\n      <td>0.697194</td>\n      <td>0.063729</td>\n      <td>-0.061041</td>\n      <td>-0.336808</td>\n      <td>...</td>\n      <td>-0.447420</td>\n      <td>-0.489593</td>\n      <td>-0.637586</td>\n      <td>-0.570963</td>\n      <td>0.421161</td>\n      <td>-0.205135</td>\n      <td>-0.238691</td>\n      <td>0.157226</td>\n      <td>-0.744223</td>\n      <td>-0.297976</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>252</td>\n      <td>0.179165</td>\n      <td>0.050252</td>\n      <td>-1.559113</td>\n      <td>-0.208699</td>\n      <td>2.996405</td>\n      <td>1.089666</td>\n      <td>0.169657</td>\n      <td>-0.199713</td>\n      <td>0.011201</td>\n      <td>...</td>\n      <td>-0.272914</td>\n      <td>-0.772601</td>\n      <td>-1.286773</td>\n      <td>-0.605035</td>\n      <td>0.342517</td>\n      <td>0.162946</td>\n      <td>-0.581229</td>\n      <td>-0.558160</td>\n      <td>-0.167480</td>\n      <td>-0.208152</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>253</td>\n      <td>0.719092</td>\n      <td>1.957038</td>\n      <td>-9.073939</td>\n      <td>-1.067257</td>\n      <td>9.791842</td>\n      <td>9.566616</td>\n      <td>1.057602</td>\n      <td>-0.367063</td>\n      <td>0.284872</td>\n      <td>...</td>\n      <td>-1.418733</td>\n      <td>-1.232353</td>\n      <td>-4.137112</td>\n      <td>0.878891</td>\n      <td>2.284428</td>\n      <td>0.125582</td>\n      <td>-2.409629</td>\n      <td>-3.088445</td>\n      <td>-0.943358</td>\n      <td>-0.822677</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>254</td>\n      <td>0.047629</td>\n      <td>0.026461</td>\n      <td>-3.082912</td>\n      <td>-0.203656</td>\n      <td>0.456576</td>\n      <td>0.884993</td>\n      <td>0.062528</td>\n      <td>0.145023</td>\n      <td>0.050536</td>\n      <td>...</td>\n      <td>0.103100</td>\n      <td>-0.251306</td>\n      <td>-0.537388</td>\n      <td>-0.611182</td>\n      <td>0.294958</td>\n      <td>-0.166037</td>\n      <td>-0.286224</td>\n      <td>-0.185726</td>\n      <td>-0.943598</td>\n      <td>-0.283262</td>\n    </tr>\n  </tbody>\n</table>\n<p>255 rows Ã— 18212 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T14:18:26.892059Z","iopub.execute_input":"2024-07-11T14:18:26.892915Z","iopub.status.idle":"2024-07-11T14:18:35.086481Z","shell.execute_reply.started":"2024-07-11T14:18:26.892881Z","shell.execute_reply":"2024-07-11T14:18:35.085457Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}